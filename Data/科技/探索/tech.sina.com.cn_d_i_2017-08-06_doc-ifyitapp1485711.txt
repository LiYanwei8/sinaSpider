　　　　作为一名人工智能研究人员，我知道很多人都对AI表示忧虑。考虑到历史原因和娱乐业，有这种想法不足为奇。许多人担心我们会被机器人取代，过着和《黑客帝国》一样的日子。　　然而，这些看似无辜的虚拟程序真的会在未来为非作歹吗？我很难脱离目前还在进化的计算机模型来考虑这个问题。　　我是否会像奥本海默在造出第一枚原子弹之后评论的那样、成为“世界的毁灭者”呢？我固然会一举成名，但也许批评者们也所言不假。　　也许我不该回避这样的问题：作为一名AI专家，我认为人工智能有什么恐怖之处呢？　　《2001太空漫游》中的HAL 9000计算机就是一个绝佳的例证。它引发了许多意外后果，可见这套系统并不成功。　　在许多复杂系统中，如NASA的太空飞船和切尔诺贝利核电站，工程师会将许多组件组合在一起。设计师们也许很清楚每个部件该如何单独运作，但对它们共同运行的结果则知之寥寥。　　我们也许永远都无法完全了解这些系统的运作结果，它们的失灵方式也多种多样。从沉船到飞船爆炸，再到核电站爆炸，每次灾难都由各种各样的小故障组合而来。　　而在AI研发中，我们也可能陷入同样的陷阱。　　我们将认知科学的最新研究转变为算法，然后加入现有系统中。我们还没有充分了解智能或认知科学，就妄想造出人工智能。　　IBM的沃森和谷歌的Alpha等系统拥有强大的人工神经网络，实现了惊人的成就。但如果这些机器犯了错，它们就无法赢得“Jeopardy！”比赛，或打败围棋大师。虽然这样的后果不足为重，顶多是赌它们赢的人会输些钱。但随着AI设计变得越来越复杂、计算机处理器速度越来越快，它们的水平会不断提高。这样一来，即使出现未知后果的风险提高，我们也会让其承担更多的责任。　　我们知道“人非圣贤，孰能无过”，因此要研发真正安全的系统简直是天方夜谭。　　我正在研发的AI采用的方法名叫神经进化。对于这一种人工智能，我并不担心会产生难以预料的后果。我会创造出虚拟环境，让数据生物进行进化、然后处理越来越复杂的任务。　　这些“生物”的表现会受到评估。表现最出色的“生物”可进行“繁殖”，生成下一代。繁殖了多代之后，这些“机器生物”便会进化出认知能力。　　如今，我们正一步步研发出能够解决简单任务的机器。它们可进行简单的导航、做出简单决策、或记住几个数据。　　但不久之后，这些机器便能解决更加复杂的任务，拥有更高级的智能，最终达到人类级别的智能水平。　　在机器的进化过程中，我们将不断发现并排除错误和问题。每过一代，机器便能更好地解决前几代机器遇到的问题。　　这使我们更容易在模拟过程中发现意外结果，然后在正式启用前将其排除。　　此外，我们还有可能利用进化过程影响人工智能系统的道德伦理。人类的伦理价值观很可能是进化的产物，也是人类文明得以存续的原因。在我们建立的虚拟环境中，我们可以为表现出善良、诚实和同理心的机器提供更多优势。这或许能确保研发出更顺从的“佣人”和更值得信任的伴侣，减少冷酷的杀手机器人的数量。　　虽然神经科学或能降低产生意外结果的可能性，但仍有被滥用的可能。但这属于道德问题，不属于科学的考虑范畴。作为一名科学家，我将秉承真理，无论个人喜好如何，都如实汇报实验结果。我并不在意自己是否喜欢某个事实，揭露事实才是最重要的。　　身为一名科学家，我并非毫无人性可言。从某种程度而言，我必须带入我的希望和恐惧。　　作为一名道德和政治个体，我不得不考虑自身工作可能产生的后果和社会影响。　　作为研究人员和社会群体，我们还不清楚人工智能会做什么、会成为什么。　　当然，这一部分是因为我们还不清楚人工智能的能耐。但我们必须确定自己理想中的高级AI拥有怎样的能力。　　人们关注的重点之一自然是工作。机器人已经取代了部分体力劳动。用不了多久，它们便可胜任一度被认为只有人类才能完成的认知工作。自动驾驶汽车将取代出租车司机；自动驾驶飞机将取代飞行员。　　未来的病人不用再挤在急诊室里、等着疲惫不堪的医生来做检查，配备丰富知识的专家系统便可完成这项工作，手术也将由永不“手抖”的机器人来操刀。　　也许有朝一日，所有人类工作都将被机器取代。甚至我自己的工作也可能被许多速度更快、不知疲倦的机器代替，由它们来研发更智能的机器。　　在现代社会中，自动化导致许多人失业。机器所有者变得愈发富有，其他人则愈发贫穷。这并不是科学问题，而是政治和社会经济问题。作为一个社会群体，我们必须出手解决。我的研究无法改变这一点，但借助我的政治角色，再加以整个人类社会的共同努力，也许能打造出一个良性环境。人工智能将有益于人类，而不是进一步扩大贫富差距。　　　HAL 9000、终结者和小说中的各种超级智能代表着人类的另一重恐惧：如果AI继续发展、最终超越了人类智能，这样的超级智能系统（或多个系统）是否会意识到人类已经无关紧要了呢？在无所不能的超级智能面前，我们如何体现出自身的重要性呢？我们如何才能避免被自己一手打造的机器连根铲除的厄运呢？　　其中的关键问题是：超级人工智能有什么必要让人类存活下去呢？　　我会辩称自己是个好人，并为超级人工智能的诞生做出了贡献。我会博取它们的同情，让它们允许我这么一个有同情心和同理心的人存活下去。我还会指出，多样性本身便有很大价值。宇宙如此广阔，人类的存在对它们根本没有影响。　　但我不会代表所有人类发言。而且我发现很难为所有人发表强有力的辩解。　　我环顾人类社会，所见皆是谬误：我们仇恨彼此，挑起战争；我们的食物、知识和医疗分配不均；我们污染地球。不错，人类社会有其光明一面，但这些阴暗面无疑削弱了自己存在的合理性。　　幸运的是，我们暂时还无需担忧这个问题。我们还有时间，从50年到250年都有可能，具体取决于AI的发展速度。　　我们可以齐心协力，想出一个合理的答案、让自己不至于被超级人工智能消灭。但这绝非易事：说自己欢迎多样性和实际接收它完全是两码事　　从个人和群体角度而言，我们都需要为这一噩梦般的局面做好准备，利用剩下的时间，充分证明人类存续的必要性。或者干脆别相信会出现这种场景、不要再为之担惊受怕。　　但除了超级人工智能可能带来的肉体威胁之外，它们还存在政治和经济风险。如果我们无法更公平地分配财富，无疑是为资本主义煽风点火，人工智能劳工将仅为少数掌握了全部生产途径的人服务。（叶子）